{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-66d28020026c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conda activate tensorflow '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "#Importing Librabries\n",
    "\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic=  mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable =False \n",
    "    results = model.process(image)\n",
    "    image.flags.writeable =True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##rendering Landmarks \n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks2(image,result):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                              mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius =1 ),\n",
    "                              mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius =1 )\n",
    "                              \n",
    "                             \n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(80,22,10),thickness=2,circle_radius =1 ),\n",
    "                              mp_drawing.DrawingSpec(color=(80,44,10),thickness=2,circle_radius =1 )\n",
    "                              )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(80,22,10),thickness=2,circle_radius =1 ),\n",
    "                              mp_drawing.DrawingSpec(color=(80,44,10),thickness=2,circle_radius =1 )\n",
    "                              )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(80,117,10),thickness=2,circle_radius =1 ),\n",
    "                              mp_drawing.DrawingSpec(color=(80,66,10),thickness=2,circle_radius =1 )\n",
    "                              )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tracking Face and Hands\n",
    "i = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        #Using Mediapipe\n",
    "\n",
    "        image, results = mediapipe_detection(frame, holistic)   \n",
    "        \n",
    "        #Drawing Ladmarks\n",
    "        draw_landmarks2(image,results)\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"frame\" , image)\n",
    "       # cv2.imwrite(\"image.jpg\", image)\n",
    "        if cv2.waitKey(1)==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e2dd042c616c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_keypoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "##Extracting Landmarks \n",
    "\"\"\"pose =[]\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x,res.y,res.z,res.visibility])\n",
    "    pose.append(test)\"\"\"\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    \n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    \n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    \n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "test = extract_keypoints(results)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"mp_data/\")\n",
    "actions= np.array(['Thankyou', \"Hello\", \"Which\",\"To_save\"])\n",
    "#actions= np.array([\"To_save\"])\n",
    "\n",
    "no_sequences =30 #30 Videos for each actions\n",
    "sequence_length = 30 ##30 Frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Folders \n",
    "\n",
    "for action in actions:\n",
    "    for s in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(data_path, action, str(s)))\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##collecting images\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    for action in actions:\n",
    "        for s in range(no_sequences):\n",
    "            for i in range(sequence_length):\n",
    "                \n",
    "            \n",
    "        \n",
    "                ret, frame = cap.read()\n",
    "                #Using Mediapipe\n",
    "\n",
    "                image, results = mediapipe_detection(frame, holistic)   \n",
    "\n",
    "                #Drawing Ladmarks\n",
    "                draw_landmarks2(image,results)\n",
    "\n",
    "                if i==0:\n",
    "                    cv2.putText(image, \"Starting\", (120,200), cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),4,cv2.LINE_AA)\n",
    "                    cv2.putText(image, \"Collecting Fraes for  {} Video Number {}\".format(action,s ), (15,12), cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "                    cv2.waitKey(1000)\n",
    "                else:\n",
    "                    cv2.putText(image, \"Collecting Frames for  {} Video Number {}\".format(action,s), (15,12), cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(data_path, action,str(s),str(i))\n",
    "                np.save(npy_path,keypoints)\n",
    "                cv2.imshow(\"frame\" , image)\n",
    "\n",
    "                # cv2.imwrite(\"image.jpg\", image)\n",
    "                if cv2.waitKey(1)==ord('q'):\n",
    "                    break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Thankyou': 0, 'Hello': 1, 'Which': 2, 'To_save': 3}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_map = {label:num for num,label in enumerate(actions)}\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30, 1662)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences, labels = [],[]\n",
    "for action in actions:\n",
    "    for seq in range(no_sequences):\n",
    "        window=[]\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(data_path,action , str(seq),\"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "        \n",
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30, 1662)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(labels).astype(int)\n",
    "X = np.array(sequences)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SPlitting Data\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(X,y,test_size = 0.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 4)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114 samples\n",
      "Epoch 1/120\n",
      "114/114 [==============================] - 3s 30ms/sample - loss: 1.8895 - categorical_accuracy: 0.2456\n",
      "Epoch 2/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 5.1910 - categorical_accuracy: 0.1842\n",
      "Epoch 3/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 2.2522 - categorical_accuracy: 0.2193\n",
      "Epoch 4/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 2.9403 - categorical_accuracy: 0.3684\n",
      "Epoch 5/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 2.0115 - categorical_accuracy: 0.1754\n",
      "Epoch 6/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 2.0290 - categorical_accuracy: 0.2982\n",
      "Epoch 7/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.2250 - categorical_accuracy: 0.3596\n",
      "Epoch 8/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.3521 - categorical_accuracy: 0.4386\n",
      "Epoch 9/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.1584 - categorical_accuracy: 0.4386\n",
      "Epoch 10/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.0126 - categorical_accuracy: 0.4912\n",
      "Epoch 11/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.1912 - categorical_accuracy: 0.4211\n",
      "Epoch 12/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.8860 - categorical_accuracy: 0.4474\n",
      "Epoch 13/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 5.3235 - categorical_accuracy: 0.3596\n",
      "Epoch 14/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.8442 - categorical_accuracy: 0.2456\n",
      "Epoch 15/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.6106 - categorical_accuracy: 0.3772\n",
      "Epoch 16/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.4485 - categorical_accuracy: 0.1579\n",
      "Epoch 17/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.3857 - categorical_accuracy: 0.1228\n",
      "Epoch 18/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.2602 - categorical_accuracy: 0.4474\n",
      "Epoch 19/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.1470 - categorical_accuracy: 0.5175\n",
      "Epoch 20/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.0763 - categorical_accuracy: 0.5263\n",
      "Epoch 21/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.9430 - categorical_accuracy: 0.6228\n",
      "Epoch 22/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.8466 - categorical_accuracy: 0.6316\n",
      "Epoch 23/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7776 - categorical_accuracy: 0.6228\n",
      "Epoch 24/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.2450 - categorical_accuracy: 0.5175\n",
      "Epoch 25/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.1492 - categorical_accuracy: 0.4737\n",
      "Epoch 26/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.0520 - categorical_accuracy: 0.4737\n",
      "Epoch 27/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.8362 - categorical_accuracy: 0.6228\n",
      "Epoch 28/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7633 - categorical_accuracy: 0.6754\n",
      "Epoch 29/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7909 - categorical_accuracy: 0.6228\n",
      "Epoch 30/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.1402 - categorical_accuracy: 0.4912\n",
      "Epoch 31/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.1580 - categorical_accuracy: 0.4386\n",
      "Epoch 32/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 1.1801 - categorical_accuracy: 0.4035\n",
      "Epoch 33/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.9149 - categorical_accuracy: 0.6053\n",
      "Epoch 34/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.8015 - categorical_accuracy: 0.6579\n",
      "Epoch 35/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7342 - categorical_accuracy: 0.6228\n",
      "Epoch 36/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7165 - categorical_accuracy: 0.6228\n",
      "Epoch 37/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7208 - categorical_accuracy: 0.6842\n",
      "Epoch 38/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7241 - categorical_accuracy: 0.6930\n",
      "Epoch 39/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7673 - categorical_accuracy: 0.6579\n",
      "Epoch 40/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.8286 - categorical_accuracy: 0.5439\n",
      "Epoch 41/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5662 - categorical_accuracy: 0.6667\n",
      "Epoch 42/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5896 - categorical_accuracy: 0.7105\n",
      "Epoch 43/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5157 - categorical_accuracy: 0.7632\n",
      "Epoch 44/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5226 - categorical_accuracy: 0.7368\n",
      "Epoch 45/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.4722 - categorical_accuracy: 0.7982\n",
      "Epoch 46/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.4713 - categorical_accuracy: 0.7807\n",
      "Epoch 47/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7636 - categorical_accuracy: 0.7018\n",
      "Epoch 48/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7815 - categorical_accuracy: 0.6491\n",
      "Epoch 49/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.6104 - categorical_accuracy: 0.7281\n",
      "Epoch 50/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5902 - categorical_accuracy: 0.7193\n",
      "Epoch 51/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5964 - categorical_accuracy: 0.7632\n",
      "Epoch 52/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.6025 - categorical_accuracy: 0.7632\n",
      "Epoch 53/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5103 - categorical_accuracy: 0.7719\n",
      "Epoch 54/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5126 - categorical_accuracy: 0.7632\n",
      "Epoch 55/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.6050 - categorical_accuracy: 0.7368\n",
      "Epoch 56/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.4232 - categorical_accuracy: 0.8333\n",
      "Epoch 57/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3533 - categorical_accuracy: 0.8684\n",
      "Epoch 58/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2876 - categorical_accuracy: 0.9123\n",
      "Epoch 59/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2988 - categorical_accuracy: 0.8947\n",
      "Epoch 60/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2676 - categorical_accuracy: 0.8772\n",
      "Epoch 61/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3068 - categorical_accuracy: 0.8772\n",
      "Epoch 62/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5376 - categorical_accuracy: 0.8070\n",
      "Epoch 63/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2652 - categorical_accuracy: 0.9035\n",
      "Epoch 64/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1992 - categorical_accuracy: 0.9298\n",
      "Epoch 65/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1548 - categorical_accuracy: 0.9561\n",
      "Epoch 66/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2842 - categorical_accuracy: 0.8860\n",
      "Epoch 67/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.6947 - categorical_accuracy: 0.7368\n",
      "Epoch 68/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7564 - categorical_accuracy: 0.7632\n",
      "Epoch 69/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7150 - categorical_accuracy: 0.7193\n",
      "Epoch 70/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.6230 - categorical_accuracy: 0.7895\n",
      "Epoch 71/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3745 - categorical_accuracy: 0.8421\n",
      "Epoch 72/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.4492 - categorical_accuracy: 0.7719\n",
      "Epoch 73/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3168 - categorical_accuracy: 0.8772\n",
      "Epoch 74/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2579 - categorical_accuracy: 0.8772\n",
      "Epoch 75/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1995 - categorical_accuracy: 0.9298\n",
      "Epoch 76/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2400 - categorical_accuracy: 0.8947\n",
      "Epoch 77/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1814 - categorical_accuracy: 0.9561\n",
      "Epoch 78/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2313 - categorical_accuracy: 0.9123\n",
      "Epoch 79/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1147 - categorical_accuracy: 0.9649\n",
      "Epoch 80/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1160 - categorical_accuracy: 0.9649\n",
      "Epoch 81/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.0945 - categorical_accuracy: 0.9737\n",
      "Epoch 82/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1080 - categorical_accuracy: 0.9649\n",
      "Epoch 83/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1517 - categorical_accuracy: 0.9561\n",
      "Epoch 84/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2493 - categorical_accuracy: 0.9123\n",
      "Epoch 85/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1434 - categorical_accuracy: 0.9211\n",
      "Epoch 86/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1250 - categorical_accuracy: 0.9649\n",
      "Epoch 87/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.0792 - categorical_accuracy: 0.9912\n",
      "Epoch 88/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.0513 - categorical_accuracy: 0.9912\n",
      "Epoch 89/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1627 - categorical_accuracy: 0.9386\n",
      "Epoch 90/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.7218 - categorical_accuracy: 0.7807\n",
      "Epoch 91/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.9988 - categorical_accuracy: 0.5175\n",
      "Epoch 92/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.9756 - categorical_accuracy: 0.6140\n",
      "Epoch 93/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.6526 - categorical_accuracy: 0.7018\n",
      "Epoch 94/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.6713 - categorical_accuracy: 0.7368\n",
      "Epoch 95/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5437 - categorical_accuracy: 0.76320s - loss: 0.5575 - categorical_accuracy: 0.76\n",
      "Epoch 96/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.4653 - categorical_accuracy: 0.8421\n",
      "Epoch 97/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2886 - categorical_accuracy: 0.9123\n",
      "Epoch 98/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3150 - categorical_accuracy: 0.9035\n",
      "Epoch 99/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5028 - categorical_accuracy: 0.7544\n",
      "Epoch 100/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.8751 - categorical_accuracy: 0.6930\n",
      "Epoch 101/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.8622 - categorical_accuracy: 0.5702\n",
      "Epoch 102/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.6443 - categorical_accuracy: 0.6930\n",
      "Epoch 103/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5735 - categorical_accuracy: 0.7982\n",
      "Epoch 104/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.5316 - categorical_accuracy: 0.8509\n",
      "Epoch 105/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.4572 - categorical_accuracy: 0.8684\n",
      "Epoch 106/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.4495 - categorical_accuracy: 0.8070\n",
      "Epoch 107/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3525 - categorical_accuracy: 0.86840s - loss: 0.3232 - categorical_accuracy: 0.88\n",
      "Epoch 108/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3143 - categorical_accuracy: 0.8684\n",
      "Epoch 109/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3074 - categorical_accuracy: 0.8860\n",
      "Epoch 110/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2370 - categorical_accuracy: 0.9035\n",
      "Epoch 111/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2304 - categorical_accuracy: 0.9211\n",
      "Epoch 112/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.1814 - categorical_accuracy: 0.9474\n",
      "Epoch 113/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3842 - categorical_accuracy: 0.8421\n",
      "Epoch 114/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2369 - categorical_accuracy: 0.8947\n",
      "Epoch 115/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2821 - categorical_accuracy: 0.8772\n",
      "Epoch 116/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2438 - categorical_accuracy: 0.9123\n",
      "Epoch 117/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3143 - categorical_accuracy: 0.8947\n",
      "Epoch 118/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2809 - categorical_accuracy: 0.8860\n",
      "Epoch 119/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.3237 - categorical_accuracy: 0.8772\n",
      "Epoch 120/120\n",
      "114/114 [==============================] - 1s 6ms/sample - loss: 0.2704 - categorical_accuracy: 0.8947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f6b1b5f48>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences = True, activation = 'relu',input_shape= (30,1662)))\n",
    "model.add(LSTM(128,return_sequences= True, activation = 'relu'))\n",
    "model.add(LSTM(64,return_sequences= False, activation = 'relu'))\n",
    "model.add(Dense(64,activation= 'relu'))\n",
    "model.add(Dense(32,activation= 'relu'))\n",
    "model.add(Dense(actions.shape[0],activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer= \"adam\", loss = \"categorical_crossentropy\",metrics=['categorical_accuracy'])\n",
    "model.fit(X_train, y_train, epochs = 120,callbacks= [tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.8531968e-03 6.4982436e-05 5.7496753e-02 9.3958515e-01]\n",
      " [1.8043153e-03 4.6110497e-05 3.7223071e-02 9.6092641e-01]\n",
      " [5.6907747e-02 7.7199645e-04 7.6205307e-01 1.8026720e-01]\n",
      " [2.0769945e-01 9.4497873e-04 7.8747678e-01 3.8787862e-03]\n",
      " [8.5451204e-05 2.8950114e-06 1.9769613e-03 9.9793470e-01]\n",
      " [2.3082343e-03 9.9765718e-01 3.4458910e-05 1.5960715e-07]]\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To_save\n",
      "To_save\n"
     ]
    }
   ],
   "source": [
    "print(actions[np.argmax(res[0])])\n",
    "\n",
    "print(actions[np.argmax(y_test[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[83,  1],\n",
       "        [ 5, 25]],\n",
       "\n",
       "       [[85,  0],\n",
       "        [ 1, 28]],\n",
       "\n",
       "       [[81,  5],\n",
       "        [ 1, 27]],\n",
       "\n",
       "       [[86,  1],\n",
       "        [ 0, 27]]], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##MODEL EVALUATION\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix,accuracy_score\n",
    "yhat = model.predict(X_train)\n",
    "\n",
    "ytrue= np.argmax(y_train,axis =1 ).tolist()\n",
    "yhat = np.argmax(yhat,axis = 1 ).tolist()\n",
    "\n",
    "multilabel_confusion_matrix(ytrue, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue , yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Thankyou\n",
      "Thankyou\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "To_save\n",
      "Which\n",
      "Which\n",
      "Which\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Thankyou\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "##Final testing\n",
    "import tensorflow as tf\n",
    "sequences = []#concatenating 30 frames\n",
    "sentences = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        #Using Mediapipe\n",
    "\n",
    "        image, results = mediapipe_detection(frame, holistic)   \n",
    "        \n",
    "        #Drawing Ladmarks\n",
    "        draw_landmarks2(image,results)\n",
    "        \n",
    "        ##making predictions\n",
    "        \n",
    "        keypoints = extract_keypoints(results)\n",
    "        #sequences.insert(0,keypoints)\n",
    "        sequences.append(keypoints)\n",
    "        sequences = sequences[-30:]\n",
    "        \n",
    "        if len(sequences)==30:\n",
    "            res = model.predict(np.expand_dims(sequences,axis = 0))[0]\n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res):\n",
    "                if res[np.argmax(res)]>threshold:\n",
    "                    print(actions[np.argmax(res)])\n",
    "                    if len(sentences)>0:\n",
    "                        if actions[np.argmax(res)]!=sentences[-1]:\n",
    "                            sentences.append(actions[np.argmax(res)])\n",
    "                            \n",
    "                    else:\n",
    "                        sentences.append(actions[np.argmax(res)])\n",
    "            if len(sentences)>5:\n",
    "                sentences = sentences[-5:]\n",
    "\n",
    "        cv2.rectangle(image, (0,0),(640,40), (245,117,16),-1 )\n",
    "        cv2.putText(image,\"\".join(sentences),(3,30),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"frame\" , image)\n",
    "       # cv2.imwrite(\"image.jpg\", image)\n",
    "        if cv2.waitKey(1)==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
